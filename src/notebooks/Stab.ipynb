{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb728412",
   "metadata": {},
   "source": [
    "Importação da etapa de pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6cbd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../STab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7123d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_processing import ChurnDataProcessor\n",
    "from STab import MainModel, Num_Cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f194e6",
   "metadata": {},
   "source": [
    "Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc68042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import ks_2samp\n",
    "import keras4torch\n",
    "from keras4torch.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa7dfe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração de semente para reprodutibilidade\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9340b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.abspath('../../data/customer_churn_telecom_services.csv')\n",
    "processor = ChurnDataProcessor(file_path)\n",
    "processor.split_and_balance() # realizar apenas a divisão dos dados, porque vamos usar técnicas de tratamento diferentes para o STab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc8c5ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados e divididos.\n",
      "Treino: (5174, 20)\n",
      "Validação: (2586, 20)\n",
      "Teste: (1761, 20)\n"
     ]
    }
   ],
   "source": [
    "#Log de verificação dos dados\n",
    "print(f\"Dados carregados e divididos.\")\n",
    "print(f\"Treino: {processor.train_df.shape}\")\n",
    "print(f\"Validação: {processor.validation_df.shape}\")\n",
    "print(f\"Teste: {processor.test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf9a13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados transformados para STab.\n",
      "Cardinalidades das categorias: [3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "def prepare_data_for_stab(processor):\n",
    "    \"\"\"\n",
    "    Prepara os dados do processor para o formato específico do STab:\n",
    "    - Numéricas: StandardScaler\n",
    "    - Categóricas: LabelEncoder (Inteiros)\n",
    "    - Retorno: Listas [X_num, X_cat] compatíveis com Num_Cat\n",
    "    \"\"\"\n",
    "    # Cópias para não alterar o original\n",
    "    train_df = processor.train_df.copy()\n",
    "    val_df = processor.validation_df.copy()\n",
    "    test_df = processor.test_df.copy()\n",
    "\n",
    "    # Tratamento de Nulos\n",
    "    for df in [train_df, val_df, test_df]:\n",
    "        df['TotalCharges'] = df['TotalCharges'].fillna(0.0)\n",
    "\n",
    "    # Definição de Colunas\n",
    "    target_col = 'Churn'\n",
    "    num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "    # Todas as outras colunas (exceto target e numéricas) são categóricas\n",
    "    cat_cols = [c for c in train_df.columns if c not in num_cols + [target_col]]\n",
    "\n",
    "    # 1. Processamento Numérico (StandardScaler)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_num = scaler.fit_transform(train_df[num_cols]).astype(np.float32)\n",
    "    X_val_num = scaler.transform(val_df[num_cols]).astype(np.float32)\n",
    "    X_test_num = scaler.transform(test_df[num_cols]).astype(np.float32)\n",
    "\n",
    "    # 2. Processamento Categórico (LabelEncoder)\n",
    "    cat_cardinalities = []\n",
    "    \n",
    "    # Matrizes para guardar os índices inteiros\n",
    "    X_train_cat = np.zeros((len(train_df), len(cat_cols)), dtype=np.int64)\n",
    "    X_val_cat = np.zeros((len(val_df), len(cat_cols)), dtype=np.int64)\n",
    "    X_test_cat = np.zeros((len(test_df), len(cat_cols)), dtype=np.int64)\n",
    "\n",
    "    for i, col in enumerate(cat_cols):\n",
    "        le = LabelEncoder()\n",
    "        # Treina com todos os dados possíveis para não dar erro de categoria desconhecida\n",
    "        all_data = pd.concat([train_df[col], val_df[col], test_df[col]])\n",
    "        le.fit(all_data.astype(str))\n",
    "        \n",
    "        X_train_cat[:, i] = le.transform(train_df[col].astype(str))\n",
    "        X_val_cat[:, i] = le.transform(val_df[col].astype(str))\n",
    "        X_test_cat[:, i] = le.transform(test_df[col].astype(str))\n",
    "        \n",
    "        # Guarda a cardinalidade (+1 para segurança)\n",
    "        cat_cardinalities.append(len(le.classes_) + 1)\n",
    "\n",
    "    # 3. Targets\n",
    "    le_target = LabelEncoder()\n",
    "    y_train = torch.tensor(le_target.fit_transform(train_df[target_col]), dtype=torch.long)\n",
    "    y_val = torch.tensor(le_target.transform(val_df[target_col]), dtype=torch.long)\n",
    "    y_test = torch.tensor(le_target.transform(test_df[target_col]), dtype=torch.long)\n",
    "\n",
    "    return (\n",
    "        [X_train_num, X_train_cat], y_train,\n",
    "        [X_val_num, X_val_cat], y_val,\n",
    "        [X_test_num, X_test_cat], y_test,\n",
    "        cat_cardinalities,\n",
    "        len(num_cols)\n",
    "    )\n",
    "\n",
    "# Executa a preparação\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, categories_list, num_continuous = prepare_data_for_stab(processor)\n",
    "\n",
    "print(f\"Dados transformados para STab.\")\n",
    "print(f\"Cardinalidades das categorias: {categories_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b79272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # --- Espaço de Busca ---\n",
    "    params = {\n",
    "        'dim': trial.suggest_categorical('dim', [8, 16, 32, 64]),\n",
    "        'depth': trial.suggest_int('depth', 1, 6),\n",
    "        'heads': trial.suggest_categorical('heads', [2, 4, 8]),\n",
    "        'attn_dropout': trial.suggest_float('attn_dropout', 0.0, 0.5),\n",
    "        'ff_dropout': trial.suggest_float('ff_dropout', 0.0, 0.5),\n",
    "        'U': trial.suggest_int('U', 1, 4), \n",
    "        'cases': trial.suggest_categorical('cases', [8, 16]),\n",
    "        'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    }\n",
    "\n",
    "    # Instanciando o Modelo Base (MainModel)\n",
    "    base_model = MainModel(\n",
    "        categories=tuple(categories_list),\n",
    "        num_continuous=num_continuous,\n",
    "        dim=params['dim'],\n",
    "        dim_out=2, # Binário\n",
    "        depth=params['depth'],\n",
    "        heads=params['heads'],\n",
    "        attn_dropout=params['attn_dropout'],\n",
    "        ff_dropout=params['ff_dropout'],\n",
    "        U=params['U'],\n",
    "        cases=params['cases']\n",
    "    )\n",
    "\n",
    "    # Wrapper para Keras4Torch (Num_Cat)\n",
    "    full_model = Num_Cat(base_model, num_number=num_continuous, classes=2, Sample_size=params['dim'])\n",
    "    \n",
    "    # Construção do Modelo\n",
    "    model = keras4torch.Model(full_model).build([num_continuous, len(categories_list)])\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=F.cross_entropy, metrics=['accuracy'])\n",
    "\n",
    "    # Critério de Parada (Patience=20 conforme PDF)\n",
    "    es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    \n",
    "    # Treinamento (verbose=0 para não poluir o output)\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200, # Limite seguro para o Optuna\n",
    "        batch_size=params['batch_size'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[es],\n",
    "        verbose=0 \n",
    "    )\n",
    "    \n",
    "    # Retorna o melhor loss de validação\n",
    "    return es.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129b981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 11:34:52,082] A new study created in memory with name: no-name-282af56b-dc3c-4a49-9f4f-31d3c4adf82e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Otimização de Hiperparâmetros (Optuna) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-11-27 11:40:00,451] Trial 0 failed with parameters: {'dim': 8, 'depth': 3, 'heads': 2, 'attn_dropout': 0.038211302358524046, 'ff_dropout': 0.25118138138530394, 'U': 1, 'cases': 8, 'lr': 0.0002244931453457853, 'weight_decay': 1.0321527077852782e-05, 'batch_size': 64} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\pe006118\\AppData\\Local\\Temp\\ipykernel_15460\\1928472804.py\", line 43, in objective\n",
      "    history = model.fit(\n",
      "        X_train, y_train,\n",
      "    ...<4 lines>...\n",
      "        verbose=0\n",
      "    )\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\keras4torch\\models\\_wrapper.py\", line 248, in fit\n",
      "    return self.fit_dl(train_loader, val_loader, epochs, callbacks, verbose, use_amp, accum_grad_steps)\n",
      "           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\keras4torch\\models\\_wrapper.py\", line 137, in fit_dl\n",
      "    history = self.trainer.run(train_loader, val_loader, max_epochs=epochs, verbose=verbose, use_amp=use_amp, accum_grad_steps=accum_grad_steps)\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\keras4torch\\_training.py\", line 153, in run\n",
      "    train_metrics = self.train_on_epoch(train_loader)\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\keras4torch\\_training.py\", line 208, in train_on_epoch\n",
      "    optimizer_step()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\keras4torch\\_training.py\", line 178, in <lambda>\n",
      "    optimizer_step = lambda: self.optimizer.step()\n",
      "                             ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 517, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 82, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py\", line 247, in step\n",
      "    adam(\n",
      "    ~~~~^\n",
      "        params_with_grad,\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "    ...<19 lines>...\n",
      "        decoupled_weight_decay=group[\"decoupled_weight_decay\"],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 150, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py\", line 953, in adam\n",
      "    func(\n",
      "    ~~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<17 lines>...\n",
      "        decoupled_weight_decay=decoupled_weight_decay,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py\", line 535, in _single_tensor_adam\n",
      "    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-27 11:40:00,460] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Executa 20 tentativas (trials) - Ajuste se tiver tempo/GPU sobrando\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Otimização Concluída ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMelhores Hiperparâmetros encontrados:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     40\u001b[39m es = EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m20\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Treinamento (verbose=0 para não poluir o output)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Limite seguro para o Optuna\u001b[39;49;00m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Retorna o melhor loss de validação\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m es.best_score\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\keras4torch\\models\\_wrapper.py:248\u001b[39m, in \u001b[36mModel.fit\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    245\u001b[39m train_loader = DataLoader(train_set, shuffle=shuffle, sampler=sampler, batch_size=batch_size, num_workers=num_workers, **dl_kwargs)\n\u001b[32m    246\u001b[39m val_loader = DataLoader(val_set, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size=validation_batch_size, num_workers=num_workers, **dl_kwargs) \u001b[38;5;28;01mif\u001b[39;00m has_val \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_dl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccum_grad_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\keras4torch\\models\\_wrapper.py:137\u001b[39m, in \u001b[36mModel.fit_dl\u001b[39m\u001b[34m(self, train_loader, val_loader, epochs, callbacks, verbose, use_amp, accum_grad_steps)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compiled\n\u001b[32m    136\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.register_callbacks(callbacks)\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m history = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccum_grad_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccum_grad_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\keras4torch\\_training.py:153\u001b[39m, in \u001b[36mTrainer.run\u001b[39m\u001b[34m(self, train_loader, val_loader, max_epochs, verbose, use_amp, accum_grad_steps)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m.__fire_event(Events.ON_EPOCH_BEGIN)\n\u001b[32m    151\u001b[39m \u001b[38;5;28mself\u001b[39m.logger.on_epoch_begin(epoch, max_epochs, data_loader=train_loader)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m train_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_on_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m val_metrics = \u001b[38;5;28mself\u001b[39m.valid_on_epoch(val_loader, \u001b[38;5;28mself\u001b[39m.use_amp) \u001b[38;5;28;01mif\u001b[39;00m val_loader \u001b[38;5;28;01melse\u001b[39;00m OrderedDict()\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m.logger.on_epoch_end(epoch, train_metrics, val_metrics)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\keras4torch\\_training.py:208\u001b[39m, in \u001b[36mTrainer.train_on_epoch\u001b[39m\u001b[34m(self, data_loader)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_accum_end \u001b[38;5;129;01mor\u001b[39;00m _is_last_batch:\n\u001b[32m    207\u001b[39m     loop.prepare_for_optimizer_step(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m    211\u001b[39m y_batch_pred = y_batch_pred.detach().float()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\keras4torch\\_training.py:178\u001b[39m, in \u001b[36mTrainer.train_on_epoch.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    176\u001b[39m     loss_backward = \u001b[38;5;28;01mlambda\u001b[39;00m loss: grad_scaler.scale(loss).backward()\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     optimizer_step = \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     loss_backward = \u001b[38;5;28;01mlambda\u001b[39;00m loss: loss.backward()\n\u001b[32m    181\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     84\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pe006118\\PrevisaoChurn\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:535\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    533\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"--- Iniciando Otimização de Hiperparâmetros (Optuna) ---\")\n",
    "# Cria o estudo para MINIMIZAR a perda (loss)\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Executa 20 tentativas (trials) - Ajuste se tiver tempo/GPU sobrando\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"\\n--- Otimização Concluída ---\")\n",
    "print(\"Melhores Hiperparâmetros encontrados:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p = study.best_params\n",
    "\n",
    "print(f\"Treinando modelo final com: {best_p}\")\n",
    "\n",
    "# Recria a arquitetura com os melhores parâmetros\n",
    "final_base = MainModel(\n",
    "    categories=tuple(categories_list),\n",
    "    num_continuous=num_continuous,\n",
    "    dim=best_p['dim'],\n",
    "    dim_out=2,\n",
    "    depth=best_p['depth'],\n",
    "    heads=best_p['heads'],\n",
    "    attn_dropout=best_p['attn_dropout'],\n",
    "    ff_dropout=best_p['ff_dropout'],\n",
    "    U=best_p['U'],\n",
    "    cases=best_p['cases']\n",
    ")\n",
    "\n",
    "final_wrapper = Num_Cat(final_base, num_number=num_continuous, classes=2, Sample_size=best_p['dim'])\n",
    "final_model = keras4torch.Model(final_wrapper).build([num_continuous, len(categories_list)])\n",
    "\n",
    "optimizer = torch.optim.AdamW(final_model.parameters(), lr=best_p['lr'], weight_decay=best_p['weight_decay'])\n",
    "final_model.compile(optimizer=optimizer, loss=F.cross_entropy, metrics=['accuracy'])\n",
    "\n",
    "# Callbacks para o modelo final\n",
    "# Salva o melhor modelo da história do treinamento\n",
    "cp = ModelCheckpoint('best_stab_model.pt', monitor='val_loss', save_best_only=True)\n",
    "es_final = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = final_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=500, # Mais épocas para o modelo final\n",
    "    batch_size=best_p['batch_size'],\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[es_final, cp],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Carrega os pesos da melhor época\n",
    "final_model.load_weights('best_stab_model.pt')\n",
    "print(\"Melhor modelo carregado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predições no Conjunto de Teste ---\n",
    "logits = final_model.predict(X_test)\n",
    "# Aplica Softmax para ter probabilidades\n",
    "probs = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "y_pred_class = np.argmax(probs, axis=1)\n",
    "y_prob_churn = probs[:, 1] # Probabilidade da classe 1 (Churn)\n",
    "\n",
    "# 1. Relatório de Classificação\n",
    "print(\"\\n=== Relatório de Classificação (Teste) ===\")\n",
    "print(classification_report(y_test.numpy(), y_pred_class))\n",
    "\n",
    "# 2. Cálculo do KS (Kolmogorov-Smirnov) - MÉTRICA PRINCIPAL\n",
    "class_0_probs = y_prob_churn[y_test.numpy() == 0]\n",
    "class_1_probs = y_prob_churn[y_test.numpy() == 1]\n",
    "\n",
    "ks_stat, p_val = ks_2samp(class_0_probs, class_1_probs)\n",
    "\n",
    "print(f\"\\n=== Métrica KS (Kolmogorov-Smirnov) ===\")\n",
    "print(f\"KS Statistic: {ks_stat:.4f}\")\n",
    "print(f\"P-value: {p_val}\")\n",
    "\n",
    "if ks_stat > 0.4:\n",
    "    print(\">> Resultado: BOM/MUITO BOM (KS > 0.4)\")\n",
    "else:\n",
    "    print(\">> Resultado: REGULAR (KS < 0.4)\")\n",
    "\n",
    "# 3. Gráfico da Curva KS (Opcional, mas recomendado no PDF)\n",
    "def plot_ks_curve(y_true, y_probs):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Ordena probabilidades\n",
    "    thresholds = np.sort(y_probs)\n",
    "    \n",
    "    # Calcula CDFs empíricas\n",
    "    tpr = [] # True Positive Rate (acumulado classe 1)\n",
    "    fpr = [] # False Positive Rate (acumulado classe 0)\n",
    "    \n",
    "    n_pos = np.sum(y_true)\n",
    "    n_neg = len(y_true) - n_pos\n",
    "    \n",
    "    # Truque rápido para plotar KS\n",
    "    for th in thresholds:\n",
    "        tp = np.sum((y_probs >= th) & (y_true == 1))\n",
    "        fp = np.sum((y_probs >= th) & (y_true == 0))\n",
    "        tpr.append(tp / n_pos)\n",
    "        fpr.append(fp / n_neg)\n",
    "        \n",
    "    plt.plot(thresholds, tpr, label='Classe 1 (Churn)')\n",
    "    plt.plot(thresholds, fpr, label='Classe 0 (Não Churn)')\n",
    "    plt.title(f'Curva KS - Estatística: {ks_stat:.4f}')\n",
    "    plt.xlabel('Threshold (Probabilidade)')\n",
    "    plt.ylabel('Proporção Acumulada')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_ks_curve(y_test.numpy(), y_prob_churn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
